# -*- coding: utf-8 -*-
"""Hybrid Model (ResNet50 + EfficientNetB3).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mapx1pWAR90XK00mTQjphEsPBV0gngWw
"""

========================================
# Hybrid Model (ResNet50 + EfficientNetB3)
# ============================================

import tensorflow as tf
from tensorflow.keras.models import load_model, Model
from tensorflow.keras.layers import Dense, Dropout, Concatenate, GlobalAveragePooling2D, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# --------------------------------------------
# 1. Load Pretrained Base Models
# --------------------------------------------
resnet = load_model("/content/drive/MyDrive/resnet50_v222.keras", compile=False)
efficient = load_model("/content/drive/MyDrive/efficientnetb3_stage5_samaher_clean.keras", compile=False)
print("Models loaded successfully.")

# --------------------------------------------
# 2. Redefine Model Inputs
# --------------------------------------------
resnet_input = Input(shape=(224, 224, 3), name="resnet_input")
efficient_input = Input(shape=(224, 224, 3), name="efficient_input")

resnet_output = resnet(resnet_input)
efficient_output = efficient(efficient_input)

# Global pooling if needed
if len(resnet_output.shape) == 4:
    resnet_feat = GlobalAveragePooling2D()(resnet_output)
else:
    resnet_feat = resnet_output

if len(efficient_output.shape) == 4:
    efficient_feat = GlobalAveragePooling2D()(efficient_output)
else:
    efficient_feat = efficient_output

# --------------------------------------------
# 3. Merge and Build Final Head
# --------------------------------------------
merged = Concatenate()([resnet_feat, efficient_feat])
x = Dropout(0.4)(merged)
x = Dense(512, activation='relu')(x)
x = Dropout(0.3)(x)
final_output = Dense(7, activation='softmax')(x)

hybrid_model = Model(inputs=[resnet_input, efficient_input], outputs=final_output)

# Freeze base models
for layer in resnet.layers:
    layer.trainable = False
for layer in efficient.layers:
    layer.trainable = False

# Compile model
hybrid_model.compile(
    optimizer=Adam(learning_rate=1e-4),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

hybrid_model.save("/content/drive/MyDrive/hybrid_resnet50_efficientb3_samaher_finalfusion.keras")
print("Hybrid model built and saved successfully.")

# --------------------------------------------
# 4. Fine-Tuning Stage
# --------------------------------------------
model = load_model("/content/drive/MyDrive/hybrid_resnet50_efficientb3_samaher_finalfusion.keras", compile=False)
print("Hybrid model loaded for fine-tuning.")

for layer in model.layers[:-5]:
    layer.trainable = False
for layer in model.layers[-5:]:
    layer.trainable = True
print("Last 5 layers unfrozen for fine-tuning.")

# --------------------------------------------
# 5. Data Loading
# --------------------------------------------
train_dir = "/content/drive/MyDrive/Train"
test_dir = "/content/drive/MyDrive/Test mix"
val_split = 0.15

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    train_dir,
    image_size=(224, 224),
    batch_size=16,
    validation_split=val_split,
    subset="training",
    seed=42
)
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    train_dir,
    image_size=(224, 224),
    batch_size=16,
    validation_split=val_split,
    subset="validation",
    seed=42
)
test_ds = tf.keras.preprocessing.image_dataset_from_directory(
    test_dir,
    image_size=(224, 224),
    batch_size=16,
    shuffle=False
)
class_names = test_ds.class_names
print("Classes:", class_names)

# Dual input generator
def dual_input_generator(dataset):
    for images, labels in dataset:
        yield ([images, images], labels)

train_gen = tf.data.Dataset.from_generator(
    lambda: dual_input_generator(train_ds),
    output_signature=(
        (tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),
         tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32)),
        tf.TensorSpec(shape=(None,), dtype=tf.int32)
    )
)
val_gen = tf.data.Dataset.from_generator(
    lambda: dual_input_generator(val_ds),
    output_signature=(
        (tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),
         tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32)),
        tf.TensorSpec(shape=(None,), dtype=tf.int32)
    )
)

# --------------------------------------------
# 6. Training
# --------------------------------------------
model.compile(optimizer=Adam(learning_rate=1e-5),
              loss="sparse_categorical_crossentropy",
              metrics=["accuracy"])

checkpoint = ModelCheckpoint(
    "/content/drive/MyDrive/hybrid_stage1_best.keras",
    monitor="val_accuracy",
    save_best_only=True,
    mode="max",
    verbose=1
)
earlystop = EarlyStopping(monitor="val_loss", patience=4, restore_best_weights=True)

history = model.fit(train_gen,
                    validation_data=val_gen,
                    epochs=10,
                    callbacks=[checkpoint, earlystop])

# --------------------------------------------
# 7. Evaluation
# --------------------------------------------
print("\nEvaluating on Test Dataset...")
test_gen = tf.data.Dataset.from_generator(
    lambda: dual_input_generator(test_ds),
    output_signature=(
        (tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),
         tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32)),
        tf.TensorSpec(shape=(None,), dtype=tf.int32)
    )
)

y_true = np.concatenate([y for _, y in test_gen], axis=0)
y_pred = np.argmax(model.predict(test_gen), axis=1)

report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)
cm = confusion_matrix(y_true, y_pred)
overall_acc = np.mean(y_true == y_pred) * 100

print(f"\nOverall Accuracy: {overall_acc:.2f}%")
print("--------------------------------------------------")
print(f"{'Disease':<30}{'Precision':>12}{'Recall':>12}{'F1-Score':>12}{'Accuracy':>15}")
print("--------------------------------------------------")

for i, cls in enumerate(class_names):
    precision = report[cls]['precision'] * 100
    recall = report[cls]['recall'] * 100
    f1 = report[cls]['f1-score'] * 100
    acc = cm[i, i] / np.sum(cm[i]) * 100
    print(f"{cls:<30}{precision:>10.2f}%{recall:>12.2f}%{f1:>12.2f}%{acc:>14.2f}%")

plt.figure(figsize=(9,7))
sns.heatmap(cm, annot=True, fmt="d", cmap="YlGnBu",
            xticklabels=class_names, yticklabels=class_names)
plt.title(f"Confusion Matrix (Accuracy: {overall_acc:.2f}%)")
plt.xlabel("Predicted Label")
plt.ylabel("Actual Label")
plt.show()